{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GP Method Comparison\n",
    "\n",
    "Compare different GP training approaches focusing on:\n",
    "- Training time cost\n",
    "- Prediction accuracy (test_plot style)\n",
    "- Save all plots to save_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/u1/l/lindajin/virtualenvs/env1/lib/python3.11/site-packages/jaxlib/plugin_support.py:71: RuntimeWarning: JAX plugin jax_cuda12_plugin version 0.6.1 is installed, but it is not compatible with the installed jaxlib version 0.7.1, so it will not be used.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results will be saved to: trained_gp_models/GP_comparison_090525\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Setup save directory\n",
    "save_dir = f\"trained_gp_models/GP_comparison_{datetime.now().strftime('%m%d%y')}\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "print(f\"Results will be saved to: {save_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JAX devices: [CpuDevice(id=0)]\n",
      "Using device: TFRT_CPU_0\n",
      "JAX devices: [CpuDevice(id=0)]\n",
      "Using device: TFRT_CPU_0\n",
      "‚úÖ JAX-compatible trainer available\n",
      "‚úÖ Improved trainer available\n"
     ]
    }
   ],
   "source": [
    "# Import modules\n",
    "import importlib\n",
    "import GP_dataloader\n",
    "importlib.reload(GP_dataloader) \n",
    "from GP_dataloader import *\n",
    "import train_GP\n",
    "importlib.reload(train_GP) \n",
    "from train_GP import *\n",
    "\n",
    "# Import improved trainers with fallback\n",
    "try:\n",
    "    from src.models.jax_compat_trainer import train_simple_conditional_gp\n",
    "    COMPAT_AVAILABLE = True\n",
    "    print(\"‚úÖ JAX-compatible trainer available\")\n",
    "except ImportError:\n",
    "    COMPAT_AVAILABLE = False\n",
    "    print(\"‚ùå JAX-compatible trainer not available\")\n",
    "\n",
    "try:\n",
    "    from src.models.improved_gp_trainer import train_improved_conditional_gp\n",
    "    IMPROVED_AVAILABLE = True\n",
    "    print(\"‚úÖ Improved trainer available\")\n",
    "except ImportError:\n",
    "    IMPROVED_AVAILABLE = False\n",
    "    print(\"‚ùå Improved trainer not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 204 sims, Testing: 20 sims\n",
      "Getting gas profiles with CAP filter for 20 simulations...\n",
      "Finished getting profiles in 1360 halos.\n",
      "Profiles shape: (1360, 21), Mass shape: (1360,), Params shape: (1360, 35), PkRatio shape: (1360, 255)\n",
      "Test data: X=(1360, 291), y=(1360, 21)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "sim_indices_train = np.load('data/sparse_sampling_train_indices_random.npy')  \n",
    "sim_indices_test = sim_indices_train[:20]  # Use subset for testing\n",
    "\n",
    "print(f\"Training: {len(sim_indices_train)} sims, Testing: {len(sim_indices_test)} sims\")\n",
    "\n",
    "# Load test data\n",
    "X_test, y_test, r_bins, k_bins = prepare_GP_data(sim_indices_test, 'CAP', 'gas')\n",
    "print(f\"Test data: X={X_test.shape}, y={y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1: Original NN+GP Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Method 1: Original NN+GP Training ===\n",
      "Getting gas profiles with CAP filter for 20 simulations...\n",
      "Finished getting profiles in 1360 halos.\n",
      "Profiles shape: (1360, 21), Mass shape: (1360,), Params shape: (1360, 35), PkRatio shape: (1360, 255)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training GP for each r_bin:   0%|          | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Adamw training for r_bin 0: Initial loss = 43335.0625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training GP for each r_bin:   0%|          | 0/21 [02:21<?, ?it/s, Step=1800, Loss=5183.408203, Best=5183.408203] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r_bin 0 in 152.91s: Final loss = 5084.053711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training GP for each r_bin:   5%|‚ñç         | 1/21 [02:36<52:09, 156.49s/it, Step=1800, Loss=5183.408203, Best=5183.408203]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Adamw training for r_bin 1: Initial loss = 3734.029296875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training GP for each r_bin:   5%|‚ñç         | 1/21 [04:52<52:09, 156.49s/it, Step=1800, Loss=2684.320801, Best=2683.158691]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r_bin 1 in 149.72s: Final loss = 2680.865234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training GP for each r_bin:  10%|‚ñâ         | 2/21 [05:07<48:30, 153.19s/it, Step=1800, Loss=2684.320801, Best=2683.158691]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Adamw training for r_bin 2: Initial loss = 4219.56103515625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training GP for each r_bin:  10%|‚ñâ         | 2/21 [07:23<48:30, 153.19s/it, Step=1800, Loss=2927.848145, Best=2927.848145]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r_bin 2 in 150.12s: Final loss = 2890.435547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training GP for each r_bin:  14%|‚ñà‚ñç        | 3/21 [07:38<45:43, 152.40s/it, Step=1800, Loss=2927.848145, Best=2927.848145]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Adamw training for r_bin 3: Initial loss = 7949.49853515625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training GP for each r_bin:  14%|‚ñà‚ñç        | 3/21 [09:52<45:43, 152.40s/it, Step=1800, Loss=3535.622314, Best=3535.622314]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r_bin 3 in 147.67s: Final loss = 3530.483887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training GP for each r_bin:  19%|‚ñà‚ñâ        | 4/21 [10:07<42:47, 151.00s/it, Step=1800, Loss=3535.622314, Best=3535.622314]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Adamw training for r_bin 4: Initial loss = 16447.71484375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training GP for each r_bin:  19%|‚ñà‚ñâ        | 4/21 [10:09<42:47, 151.00s/it, Step=0, Loss=16447.714844, Best=16447.714844] "
     ]
    }
   ],
   "source": [
    "print(\"=== Method 1: Original NN+GP Training ===\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Use subset for fair comparison\n",
    "sim_subset = sim_indices_train[:20]\n",
    "gp_models_nn, best_params_nn, model_info_nn = train_NN_gp(\n",
    "    sim_subset, filterType='CAP', ptype='gas', save=False\n",
    ")\n",
    "\n",
    "nn_train_time = time.time() - start_time\n",
    "print(f\"NN+GP training time: {nn_train_time:.1f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate NN+GP predictions\n",
    "X_train_nn, y_train_nn, _, _ = prepare_GP_data(sim_subset, 'CAP', 'gas')\n",
    "\n",
    "pred_means_nn = []\n",
    "pred_vars_nn = []\n",
    "model = build_NN_gp()\n",
    "\n",
    "for i in range(len(gp_models_nn)):\n",
    "    cond_gp = model.apply(best_params_nn[i], X_test, y_train_nn[:,i])[1]\n",
    "    pred_means_nn.append(cond_gp.mean)\n",
    "    pred_vars_nn.append(cond_gp.variance)\n",
    "\n",
    "pred_means_nn = np.array(pred_means_nn)\n",
    "pred_vars_nn = np.array(pred_vars_nn)\n",
    "print(f\"NN+GP predictions shape: {pred_means_nn.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2: Hierarchical GP Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Method 2: Hierarchical GP Training ===\")\n",
    "start_time = time.time()\n",
    "\n",
    "gp_models_hier, best_params_hier, model_info_hier = train_conditional_gp(\n",
    "    sim_subset, build_hierarchical_gp, maxiter=1000,\n",
    "    filterType='CAP', ptype='gas', save=False\n",
    ")\n",
    "\n",
    "hier_train_time = time.time() - start_time\n",
    "print(f\"Hierarchical GP training time: {hier_train_time:.1f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Hierarchical GP predictions\n",
    "pred_means_hier = []\n",
    "pred_vars_hier = []\n",
    "\n",
    "for i, gp_model in enumerate(gp_models_hier):\n",
    "    _, cond_gp = gp_model.condition(y_train_nn[:, i], X_test)\n",
    "    pred_means_hier.append(cond_gp.mean)\n",
    "    pred_vars_hier.append(cond_gp.variance)\n",
    "\n",
    "pred_means_hier = np.array(pred_means_hier)\n",
    "pred_vars_hier = np.array(pred_vars_hier)\n",
    "print(f\"Hierarchical GP predictions shape: {pred_means_hier.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 3: JAX-Compatible Trainer (if available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if COMPAT_AVAILABLE:\n",
    "    print(\"=== Method 3: JAX-Compatible Training ===\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    gp_models_compat, best_params_compat, model_info_compat = train_simple_conditional_gp(\n",
    "        sim_subset, kernel_name='hierarchical', maxiter=500\n",
    "    )\n",
    "    \n",
    "    compat_train_time = time.time() - start_time\n",
    "    print(f\"JAX-Compatible training time: {compat_train_time:.1f}s\")\n",
    "    \n",
    "    # Generate predictions (simplified - use same test approach as hierarchical)\n",
    "    pred_means_compat = pred_means_hier  # Placeholder for now\n",
    "    pred_vars_compat = pred_vars_hier\n",
    "else:\n",
    "    print(\"Method 3 skipped - JAX-compatible trainer not available\")\n",
    "    compat_train_time = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 4: Improved Kernels (if available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IMPROVED_AVAILABLE:\n",
    "    print(\"=== Method 4: Improved Kernels ===\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        gp_models_improved, best_params_improved, model_info_improved = train_improved_conditional_gp(\n",
    "            sim_subset, kernel_name='multiscale', maxiter=1000\n",
    "        )\n",
    "        \n",
    "        improved_train_time = time.time() - start_time\n",
    "        print(f\"Improved kernels training time: {improved_train_time:.1f}s\")\n",
    "        \n",
    "        # Generate predictions\n",
    "        pred_means_improved = []\n",
    "        pred_vars_improved = []\n",
    "        \n",
    "        for i, gp_model in enumerate(gp_models_improved):\n",
    "            _, cond_gp = gp_model.condition(y_train_nn[:, i], X_test)\n",
    "            pred_means_improved.append(cond_gp.mean)\n",
    "            pred_vars_improved.append(cond_gp.variance)\n",
    "        \n",
    "        pred_means_improved = np.array(pred_means_improved)\n",
    "        pred_vars_improved = np.array(pred_vars_improved)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Improved kernels failed: {e}\")\n",
    "        improved_train_time = None\n",
    "else:\n",
    "    print(\"Method 4 skipped - Improved trainer not available\")\n",
    "    improved_train_time = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Time Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training time comparison plot\n",
    "methods = ['NN+GP', 'Hierarchical']\n",
    "times = [nn_train_time, hier_train_time]\n",
    "colors = ['blue', 'red']\n",
    "\n",
    "if compat_train_time is not None:\n",
    "    methods.append('JAX-Compatible')\n",
    "    times.append(compat_train_time)\n",
    "    colors.append('green')\n",
    "    \n",
    "if 'improved_train_time' in locals() and improved_train_time is not None:\n",
    "    methods.append('Improved Kernels')\n",
    "    times.append(improved_train_time)\n",
    "    colors.append('orange')\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(methods, times, color=colors, alpha=0.7)\n",
    "plt.ylabel('Training Time [s]', fontsize=14)\n",
    "plt.title('GP Training Time Comparison', fontsize=16)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, time_val in zip(bars, times):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(times)*0.01,\n",
    "             f'{time_val:.1f}s', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{save_dir}/training_time_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Training Time Summary:\")\n",
    "for method, time_val in zip(methods, times):\n",
    "    print(f\"  {method}: {time_val:.1f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Plot Comparison (Your Format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ground truth statistics\n",
    "upper = np.quantile(y_test, 0.25, axis=0)\n",
    "lower = np.quantile(y_test, 0.75, axis=0)\n",
    "median = np.median(y_test, axis=0)\n",
    "yerr_lower = np.abs(median - lower)\n",
    "yerr_upper = np.abs(upper - median)\n",
    "yerr_truth = [yerr_lower, yerr_upper]\n",
    "\n",
    "print(f\"Ground truth computed for {len(r_bins)} radius bins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main comparison plot (your format)\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 10))\n",
    "\n",
    "# Plot 1: Predictions vs Data\n",
    "ax1.errorbar(r_bins, median, yerr=yerr_truth, fmt='o', capsize=5, capthick=2, \n",
    "             linewidth=2, markersize=6, color='black', label='Ground Truth')\n",
    "\n",
    "# NN+GP predictions\n",
    "upper_pred_nn = np.quantile(pred_means_nn, 0.25, axis=1)\n",
    "lower_pred_nn = np.quantile(pred_means_nn, 0.75, axis=1)\n",
    "median_pred_nn = np.mean(pred_means_nn, axis=1)\n",
    "yerr_lower_nn = np.abs(median_pred_nn - lower_pred_nn)\n",
    "yerr_upper_nn = np.abs(upper_pred_nn - median_pred_nn)\n",
    "yerr_nn = [yerr_lower_nn, yerr_upper_nn]\n",
    "\n",
    "ax1.errorbar(r_bins, median_pred_nn, yerr=yerr_nn, fmt='s', capsize=5, \n",
    "             capthick=2, linewidth=2, markersize=6, color='blue', label='NN+GP')\n",
    "ax1.fill_between(r_bins, median_pred_nn - np.mean(np.sqrt(pred_vars_nn), axis=1), \n",
    "                 median_pred_nn + np.mean(np.sqrt(pred_vars_nn), axis=1), \n",
    "                 color='blue', alpha=0.2, label='NN+GP 1œÉ')\n",
    "\n",
    "# Hierarchical GP predictions  \n",
    "upper_pred_hier = np.quantile(pred_means_hier, 0.25, axis=1)\n",
    "lower_pred_hier = np.quantile(pred_means_hier, 0.75, axis=1)\n",
    "median_pred_hier = np.mean(pred_means_hier, axis=1)\n",
    "yerr_lower_hier = np.abs(median_pred_hier - lower_pred_hier)\n",
    "yerr_upper_hier = np.abs(upper_pred_hier - median_pred_hier)\n",
    "yerr_hier = [yerr_lower_hier, yerr_upper_hier]\n",
    "\n",
    "ax1.errorbar(r_bins, median_pred_hier, yerr=yerr_hier, fmt='^', capsize=5,\n",
    "             capthick=2, linewidth=2, markersize=6, color='red', label='Hierarchical GP')\n",
    "ax1.fill_between(r_bins, median_pred_hier - np.mean(np.sqrt(pred_vars_hier), axis=1),\n",
    "                 median_pred_hier + np.mean(np.sqrt(pred_vars_hier), axis=1), \n",
    "                 color='red', alpha=0.2, label='Hierarchical GP 1œÉ')\n",
    "\n",
    "ax1.set_yscale('log')\n",
    "ax1.legend()\n",
    "ax1.set_xlabel('Radius [Mpc/h]', fontsize=14)\n",
    "ax1.set_ylabel(r'CAP gas Profile [$M_\\odot$/h]', fontsize=14)\n",
    "ax1.set_title('GP Method Comparison: Predictions vs Ground Truth', fontsize=16)\n",
    "\n",
    "# Plot 2: Percentage Error\n",
    "percent_error = lambda pred: 100 * (pred - median) / median\n",
    "\n",
    "ax2.plot(r_bins, percent_error(median_pred_nn), marker='s', linestyle='-', \n",
    "         color='blue', linewidth=2, markersize=6, label='NN+GP Error')\n",
    "ax2.fill_between(r_bins, \n",
    "                 percent_error(median_pred_nn - np.mean(np.sqrt(pred_vars_nn), axis=1)),\n",
    "                 percent_error(median_pred_nn + np.mean(np.sqrt(pred_vars_nn), axis=1)),\n",
    "                 color='blue', alpha=0.2)\n",
    "\n",
    "ax2.plot(r_bins, percent_error(median_pred_hier), marker='^', linestyle='-',\n",
    "         color='red', linewidth=2, markersize=6, label='Hierarchical GP Error')\n",
    "ax2.fill_between(r_bins,\n",
    "                 percent_error(median_pred_hier - np.mean(np.sqrt(pred_vars_hier), axis=1)),\n",
    "                 percent_error(median_pred_hier + np.mean(np.sqrt(pred_vars_hier), axis=1)),\n",
    "                 color='red', alpha=0.2)\n",
    "\n",
    "ax2.axhline(0, color='k', linestyle='--', linewidth=1)\n",
    "ax2.set_xlabel('Radius [Mpc/h]', fontsize=14)\n",
    "ax2.set_ylabel('Percentage Error [%]', fontsize=14)\n",
    "ax2.set_title('GP Prediction Percentage Error', fontsize=16)\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{save_dir}/test_plot_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute summary metrics\n",
    "def compute_summary_metrics(pred_means, pred_vars, ground_truth, method_name):\n",
    "    pred_median = np.mean(pred_means, axis=1)\n",
    "    \n",
    "    # Only use valid (non-NaN) data points\n",
    "    valid_mask = ~(np.isnan(pred_median) | np.isnan(ground_truth))\n",
    "    \n",
    "    if not np.any(valid_mask):\n",
    "        return f\"{method_name}: No valid predictions\"\n",
    "    \n",
    "    pred_valid = pred_median[valid_mask]\n",
    "    gt_valid = ground_truth[valid_mask]\n",
    "    \n",
    "    # Compute metrics\n",
    "    mse = np.mean((pred_valid - gt_valid)**2)\n",
    "    mae = np.mean(np.abs(pred_valid - gt_valid))\n",
    "    mape = np.mean(np.abs((pred_valid - gt_valid) / gt_valid)) * 100\n",
    "    \n",
    "    # High radius performance (last 5 bins)\n",
    "    high_r_mask = valid_mask[-5:]\n",
    "    if np.any(high_r_mask):\n",
    "        high_r_mape = np.mean(np.abs((pred_median[-5:][high_r_mask] - ground_truth[-5:][high_r_mask]) / \n",
    "                                   ground_truth[-5:][high_r_mask])) * 100\n",
    "    else:\n",
    "        high_r_mape = np.nan\n",
    "    \n",
    "    return {\n",
    "        'method': method_name,\n",
    "        'mse': mse,\n",
    "        'mae': mae,\n",
    "        'mape': mape,\n",
    "        'high_radius_mape': high_r_mape,\n",
    "        'n_valid': np.sum(valid_mask)\n",
    "    }\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUMMARY METRICS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Compute metrics for all methods\n",
    "metrics_nn = compute_summary_metrics(pred_means_nn, pred_vars_nn, median, 'NN+GP')\n",
    "metrics_hier = compute_summary_metrics(pred_means_hier, pred_vars_hier, median, 'Hierarchical GP')\n",
    "\n",
    "all_metrics = [metrics_nn, metrics_hier]\n",
    "\n",
    "print(f\"{'Method':<15} {'Valid':<5} {'MSE':<10} {'MAE':<10} {'MAPE%':<8} {'HighR%':<8}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for metrics in all_metrics:\n",
    "    if isinstance(metrics, dict):\n",
    "        print(f\"{metrics['method']:<15} {metrics['n_valid']:<5} \"\n",
    "              f\"{metrics['mse']:<10.2e} {metrics['mae']:<10.2e} \"\n",
    "              f\"{metrics['mape']:<8.1f} {metrics['high_radius_mape']:<8.1f}\")\n",
    "    else:\n",
    "        print(metrics)\n",
    "\n",
    "print(f\"\\nTraining times:\")\n",
    "for method, time_val in zip(methods, times):\n",
    "    print(f\"  {method}: {time_val:.1f}s\")\n",
    "\n",
    "print(f\"\\nüìÅ All plots saved to: {save_dir}/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save summary data\n",
    "summary = {\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'training_times': dict(zip(methods, times)),\n",
    "    'metrics': {\n",
    "        'nn_gp': metrics_nn if isinstance(metrics_nn, dict) else {'error': str(metrics_nn)},\n",
    "        'hierarchical': metrics_hier if isinstance(metrics_hier, dict) else {'error': str(metrics_hier)}\n",
    "    },\n",
    "    'data_info': {\n",
    "        'n_train_sims': len(sim_subset),\n",
    "        'n_test_sims': len(sim_indices_test),\n",
    "        'n_radius_bins': len(r_bins),\n",
    "        'filter_type': 'CAP',\n",
    "        'particle_type': 'gas'\n",
    "    }\n",
    "}\n",
    "\n",
    "import json\n",
    "with open(f'{save_dir}/comparison_summary.json', 'w') as f:\n",
    "    json.dump(summary, f, indent=2, default=str)\n",
    "\n",
    "print(f\"Summary saved to: {save_dir}/comparison_summary.json\")\n",
    "print(\"\\n‚úÖ GP method comparison complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "env1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
