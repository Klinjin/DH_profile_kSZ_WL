/global/u1/l/lindajin/virtualenvs/env1/lib/python3.11/site-packages/jaxlib/plugin_support.py:71: RuntimeWarning: JAX plugin jax_cuda12_plugin version 0.6.1 is installed, but it is not compatible with the installed jaxlib version 0.7.1, so it will not be used.  warnings.warn(🌌 Physics-Informed Neural Network Training==================================================📊 GP Benchmark: 80.6% test MAPE (severe overfitting from 29% training)🎯 NN Target: <80% test MAPE + good generalization🚀 Physics-Informed Neural Network Training Demo============================================================📊 Demo Configuration:   • Simulations: 50 (scales to 1000+ for production)   • Filter: CAP (kinetic SZ)   • Particle: gas   • Expected training time: 10-20 minutes (scales to 2-8 hours)   • Physics constraints: Enabled (mass scaling, cosmology attention, PK suppression)🧠 Model Architecture:   • Physics-informed components: True, True, True   • Hidden layers: [256, 128, 64]   • Uncertainty method: ensemble (size 3)   • Physics loss weights: 0.100Loading data for 50 simulations...Getting mean gas profiles with CAP filter for 50 simulations...Finished getting mean profiles from 50 simulations.Output shape: (50, 21) vs individual halo shape would be (n_halos*50, 21)Raw data loaded:  - Profiles: (50, 21)  - Masses: (50,)  - Params: (50, 35)  - PkRatio: (50, 79)Applying data transformations...Log mass range: [13.03, 14.22]✅ Features normalized (zero mean, unit variance)Final data shapes:  - Features: (50, 115)  - Targets: (50, 21)Creating train/validation/test splits...Split created:  - Train: 40 samples (80.0%)  - Val:   5 samples (10.0%)  - Test:  5 samples (10.0%)✅ DataLoader initialized:  - Dataset size: 50 samples, 115 features  - Train/Val/Test: 40/5/5  - Batch size: 32📊 Dataset Information:   • Total samples: 50   • Features: 115 (35 cosmo + 1 mass + 79 PK)   • Target radius bins: 21   • Train/Val/Test: 40/5/5🖥️  JAX Device Configuration:   • Available devices: 1   • Default device: TFRT_CPU_0   • GPU available: False   💻 CPU training (consider GPU for faster training)🏃 Starting Training...   • Physics constraints will guide the training process   • Uncertainty estimation via deep ensemble   • Early stopping based on validation loss   • Results saved to: /pscratch/sd/l/lindajin/DH_profile_kSZ_WL/trained_gp_models/physics_nn_20250910_213034🔬 Training Physics-Informed Neural Network  - Dataset: 50 samples  - Features: 115  - Targets: 21 radius bins  - Physics constraints: Mass scaling, Cosmology attention, PK suppression  - Training config: 500 epochs, 50 patience🚀 Model initialized:  - Architecture: Physics-informed ensemble  - Physics constraints: True, True, True  - Uncertainty method: ensemble  - Ensemble size: 3Training:   0%|                                                                                                          | 0/500 [00:00<?, ?it/s]Training:   0%|                                                                                                          | 0/500 [00:02<?, ?it/s]Traceback (most recent call last):  File "/pscratch/sd/l/lindajin/DH_profile_kSZ_WL/examples/physics_neural_demo.py", line 627, in <module>    trainer, results, efficiency_results = main('demo')                                           ^^^^^^^^^^^^  File "/pscratch/sd/l/lindajin/DH_profile_kSZ_WL/examples/physics_neural_demo.py", line 520, in main    trainer, results, efficiency_results = run_physics_neural_training_demo()                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^  File "/pscratch/sd/l/lindajin/DH_profile_kSZ_WL/examples/physics_neural_demo.py", line 338, in run_physics_neural_training_demo    results = trainer.train(              ^^^^^^^^^^^^^^  File "/pscratch/sd/l/lindajin/DH_profile_kSZ_WL/examples/../src/models/physics_neural_trainer.py", line 341, in train    self.params, self.opt_state, train_loss, loss_dict = self.train_step(                                                         ^^^^^^^^^^^^^^^^  File "/pscratch/sd/l/lindajin/DH_profile_kSZ_WL/examples/../src/models/physics_neural_trainer.py", line 251, in train_step    (loss_val, loss_dict), grads = jax.value_and_grad(loss_fn, has_aux=True)(params)                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^  File "/pscratch/sd/l/lindajin/DH_profile_kSZ_WL/examples/../src/models/physics_neural_trainer.py", line 231, in loss_fn    prediction_loss = jnp.mean((pred_mean - batch_y)**2)                                ~~~~~~~~~~^~~~~~~~~  File "/global/u1/l/lindajin/virtualenvs/env1/lib/python3.11/site-packages/jax/_src/numpy/array_methods.py", line 589, in deferring_binary_op    raise TypeError(f"unsupported operand type(s) for {opchar}: "TypeError: unsupported operand type(s) for -: 'tuple' and 'ArrayImpl'--------------------For simplicity, JAX has removed its internal frames from the traceback of the following exception. Set JAX_TRACEBACK_FILTERING=off to include these.