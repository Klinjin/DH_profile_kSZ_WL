/global/u1/l/lindajin/virtualenvs/env1/lib/python3.11/site-packages/jaxlib/plugin_support.py:71: RuntimeWarning: JAX plugin jax_cuda12_plugin version 0.6.1 is installed, but it is not compatible with the installed jaxlib version 0.7.1, so it will not be used.  warnings.warn(ðŸŒŒ Physics-Informed Neural Network Training==================================================ðŸ“Š GP Benchmark: 80.6% test MAPE (severe overfitting from 29% training)ðŸŽ¯ NN Target: <80% test MAPE + good generalizationðŸš€ Physics-Informed Neural Network Training Demo============================================================ðŸ“Š Demo Configuration:   â€¢ Simulations: 50 (scales to 1000+ for production)   â€¢ Filter: CAP (kinetic SZ)   â€¢ Particle: gas   â€¢ Expected training time: 10-20 minutes (scales to 2-8 hours)   â€¢ Physics constraints: Enabled (mass scaling, cosmology attention, PK suppression)ðŸ§  Model Architecture:   â€¢ Physics-informed components: True, True, True   â€¢ Hidden layers: [256, 128, 64]   â€¢ Uncertainty method: ensemble (size 3)   â€¢ Physics loss weights: 0.100Loading data for 50 simulations...Getting mean gas profiles with CAP filter for 50 simulations...Finished getting mean profiles from 50 simulations.Output shape: (50, 21) vs individual halo shape would be (n_halos*50, 21)Raw data loaded:  - Profiles: (50, 21)  - Masses: (50,)  - Params: (50, 35)  - PkRatio: (50, 79)Applying data transformations...Log mass range: [13.03, 14.22]âœ… Features normalized (zero mean, unit variance)Final data shapes:  - Features: (50, 115)  - Targets: (50, 21)Creating train/validation/test splits...Split created:  - Train: 40 samples (80.0%)  - Val:   5 samples (10.0%)  - Test:  5 samples (10.0%)âœ… DataLoader initialized:  - Dataset size: 50 samples, 115 features  - Train/Val/Test: 40/5/5  - Batch size: 32ðŸ“Š Dataset Information:   â€¢ Total samples: 50   â€¢ Features: 115 (35 cosmo + 1 mass + 79 PK)   â€¢ Target radius bins: 21   â€¢ Train/Val/Test: 40/5/5ðŸ–¥ï¸  JAX Device Configuration:   â€¢ Available devices: 1   â€¢ Default device: TFRT_CPU_0   â€¢ GPU available: False   ðŸ’» CPU training (consider GPU for faster training)ðŸƒ Starting Training...   â€¢ Physics constraints will guide the training process   â€¢ Uncertainty estimation via deep ensemble   â€¢ Early stopping based on validation loss   â€¢ Results saved to: /pscratch/sd/l/lindajin/DH_profile_kSZ_WL/trained_gp_models/physics_nn_20250910_214304ðŸ”¬ Training Physics-Informed Neural Network  - Dataset: 50 samples  - Features: 115  - Targets: 21 radius bins  - Physics constraints: Mass scaling, Cosmology attention, PK suppression  - Training config: 500 epochs, 50 patienceðŸš€ Model initialized:  - Architecture: Physics-informed ensemble  - Physics constraints: True, True, True  - Uncertainty method: ensemble  - Ensemble size: 3Training:   0%|                                                                                                          | 0/500 [00:00<?, ?it/s]Training:   0%|â–                                                                                               | 1/500 [00:11<1:32:34, 11.13s/it]Training:   0%|â–                                                                                                 | 2/500 [00:11<40:45,  4.91s/it]Training:   1%|â–Œ                                                                                                 | 3/500 [00:12<23:32,  2.84s/it]Training:   1%|â–Š                                                                                                 | 4/500 [00:12<15:28,  1.87s/it]Training:   1%|â–‰                                                                                                 | 5/500 [00:12<11:00,  1.33s/it]Training:   1%|â–ˆâ–                                                                                                | 6/500 [00:13<08:19,  1.01s/it]Training:   1%|â–ˆâ–Ž                                                                                                | 7/500 [00:13<06:36,  1.24it/s]Training:   2%|â–ˆâ–Œ                                                                                                | 8/500 [00:13<05:30,  1.49it/s]Training:   2%|â–ˆâ–Š                                                                                                | 9/500 [00:14<04:44,  1.72it/s]Training:   2%|â–ˆâ–‰                                                                                               | 10/500 [00:14<04:14,  1.92it/s]Training:   2%|â–ˆâ–ˆâ–                                                                                              | 11/500 [00:15<03:54,  2.09it/s]Training:   2%|â–ˆâ–ˆâ–Ž                                                                                              | 12/500 [00:15<03:39,  2.23it/s]Training:   3%|â–ˆâ–ˆâ–Œ                                                                                              | 13/500 [00:15<03:28,  2.33it/s]Training:   3%|â–ˆâ–ˆâ–‹                                                                                              | 14/500 [00:16<03:21,  2.41it/s]Training:   3%|â–ˆâ–ˆâ–‰                                                                                              | 15/500 [00:16<03:16,  2.47it/s]Training:   3%|â–ˆâ–ˆâ–ˆ                                                                                              | 16/500 [00:17<03:36,  2.23it/s]Training:   3%|â–ˆâ–ˆâ–ˆâ–Ž                                                                                             | 17/500 [00:17<03:27,  2.33it/s]Training:   4%|â–ˆâ–ˆâ–ˆâ–                                                                                             | 18/500 [00:17<03:19,  2.41it/s]Training:   4%|â–ˆâ–ˆâ–ˆâ–‹                                                                                             | 19/500 [00:18<03:14,  2.47it/s]Training:   4%|â–ˆâ–ˆâ–ˆâ–‰                                                                                             | 20/500 [00:18<03:11,  2.51it/s]Training:   4%|â–ˆâ–ˆâ–ˆâ–ˆ                                                                                             | 21/500 [00:19<03:08,  2.54it/s]Training:   4%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                                                            | 22/500 [00:19<03:09,  2.52it/s]Training:   5%|â–ˆâ–ˆâ–ˆâ–ˆâ–                                                                                            | 23/500 [00:19<03:07,  2.55it/s]Training:   5%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                                                            | 24/500 [00:20<03:05,  2.57it/s]Training:   5%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                                                            | 25/500 [00:20<03:03,  2.59it/s]Training:   5%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                                            | 26/500 [00:21<03:02,  2.60it/s]Training:   5%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                                           | 27/500 [00:21<03:01,  2.60it/s]Training:   6%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                                           | 28/500 [00:21<03:01,  2.60it/s]Training:   6%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                                                           | 29/500 [00:22<03:00,  2.61it/s]Training:   6%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                                                           | 30/500 [00:22<03:00,  2.61it/s]Training:   6%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                                           | 31/500 [00:22<02:59,  2.62it/s]Training:   6%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                                          | 32/500 [00:23<02:58,  2.62it/s]Training:   7%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                                          | 33/500 [00:23<02:58,  2.61it/s]Training:   7%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                                          | 34/500 [00:24<03:19,  2.33it/s]Training:   7%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                                                          | 35/500 [00:24<03:13,  2.41it/s]Training:   7%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                                          | 36/500 [00:25<03:08,  2.46it/s]Training:   7%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                                         | 37/500 [00:25<03:04,  2.51it/s]Training:   8%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                                                         | 38/500 [00:25<03:01,  2.54it/s]Training:   8%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                                         | 39/500 [00:26<03:00,  2.56it/s]Training:   8%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                                                         | 40/500 [00:26<02:58,  2.58it/s]Training:   8%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                                         | 41/500 [00:26<02:57,  2.59it/s]Training:   8%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                                        | 42/500 [00:27<02:56,  2.60it/s]Training:   9%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                                                        | 43/500 [00:27<02:56,  2.59it/s]Training:   9%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                                        | 44/500 [00:28<02:55,  2.59it/s]Training:   9%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                                                        | 45/500 [00:28<02:54,  2.60it/s]Training:   9%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                                        | 46/500 [00:28<02:53,  2.61it/s]Training:   9%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                                        | 47/500 [00:29<02:53,  2.61it/s]Training:  10%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                                                       | 48/500 [00:29<02:52,  2.62it/s]Training:  10%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                                       | 49/500 [00:30<02:52,  2.62it/s]Early stopping at epoch 50Training:  10%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                                       | 49/500 [00:30<04:39,  1.61it/s]âœ… Training completed in 0.0 hours   Best validation loss: inf   Final test MAPE: 100.0%/pscratch/sd/l/lindajin/DH_profile_kSZ_WL/examples/../src/models/physics_neural_trainer.py:565: RuntimeWarning: invalid value encountered in subtract  val_improvement = np.maximum.accumulate(val_loss[0] - val_loss)âœ… Training Complete!   â€¢ Training time: 0.0 hours   â€¢ Best validation loss: inf   â€¢ Final test MAPE: 100.0%   â€¢ Test RÂ²: -0.639ðŸ“Š Performance vs GP Expectations:   âš ï¸  NN MAPE (100.0%) higher than GP range (29.1-35.0%)      Consider: More physics constraints, larger ensemble, more training dataðŸ“Š Training Efficiency Measurement==================================================ðŸ”¬ Efficiency Comparison:   GP (Hierarchical):     1360 samples in  42.5 min = 32.0 samples/min   NN (Physics):          3400 samples in   0.5 min = 6710.3 samples/min   Efficiency ratio:     209.7x ðŸš€ NN fasterâš–ï¸  Scaling Analysis:   Data scaling:         2.5x more samples   Time scaling:         0.0x longer training   Efficiency gain:      209.7x better data/time ratioðŸŽ¯ Apple-to-Apple Test Accuracy Comparison:   GP Best (Multiscale):    80.7% test MAPE   NN (Physics):            100.0% test MAPE   Test accuracy ratio:     1.24 âŒ WorseðŸ“ˆ Overfitting Analysis:   GP (Hierarchical): 29.1% â†’ 100.0% (3.4x overfitting)   NN (Physics):      100.0% â†’ 100.0% (1.0x âœ… Good)ðŸ† Overall Performance (MAPEÃ—time/sample, lower=better):   GP score:             2.5203   NN score:             0.0149   Overall improvement:  169.1x ðŸŽ‰ NN betterðŸ’¡ Efficiency Summary:   âš–ï¸  MIXED: Consider specific use case (scalability vs speed)ðŸ”® Making Predictions:   â€¢ Prediction shape: (3, 21)   â€¢ Uncertainty available: Yes   â€¢ Average uncertainty: 0.0024âœ… Complete! Efficiency vs GP: 209.7x